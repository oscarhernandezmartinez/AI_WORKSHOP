{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ac1435b6-79bb-4945-a508-ad50524b7510",
   "metadata": {},
   "source": [
    "###### This version adds the BM25 parameters K1 and b. BM25 has two main parameters: k1 and b. These parameters control the term frequency saturation and the document length normalization, respectively:\n",
    "\n",
    "###### k1: This parameter controls the saturation of term frequency. A higher value of k1 increases the influence of term frequency on the score. Typical values range from 1.2 to 2.0.\n",
    "###### b: This parameter controls the degree of length normalization. A value of b close to 1 means that the algorithm will heavily normalize for document length, while a value close to 0 means little normalization. Typical values range from 0.75 to 0.85.\n",
    "###### Tuning the parameters k1 and b in the BM25 algorithm can significantly impact the effectiveness of your search results. Here are some recommendations to help you tweak these parameters effectively:\n",
    "###### Understand the Parameters:\n",
    "###### k1: Controls the term frequency saturation. A higher k1 increases the influence of term frequency, making frequent terms more impactful. If your documents vary greatly in term frequency, adjusting k1 can help balance this.\n",
    "###### b: Controls the degree of length normalization. A higher b means more normalization, which is useful if document lengths vary significantly. If your documents are of similar length, a lower b might be appropriate.\n",
    "###### Experiment with Values:\n",
    "###### Start with typical values: k1 around 1.2 to 2.0 and b around 0.75 to 0.85.\n",
    "###### Test different combinations to see how they affect the ranking of your documents. You might want to use a grid search approach to systematically explore different values.\n",
    "###### Evaluate with a Test Set:\n",
    "###### Use a set of queries and known relevant documents to evaluate the effectiveness of different parameter settings.\n",
    "###### Measure performance using metrics like precision, recall, or F1-score to determine which settings yield the best results.\n",
    "###### Consider the Nature of Your Data:\n",
    "###### If your dataset has documents with highly variable lengths, consider increasing b to account for this.\n",
    "###### If term frequency is a strong indicator of relevance in your dataset, consider increasing k1.\n",
    "###### Iterative Testing:\n",
    "###### Adjust parameters incrementally and observe changes in results.\n",
    "###### Use feedback from domain experts or end-users to guide adjustments.\n",
    "###### Automated Tuning:\n",
    "###### Consider using automated hyperparameter tuning techniques, such as grid search or random search, to explore a wide range of parameter combinations efficiently.\n",
    "###### Cross-Validation:\n",
    "###### Use cross-validation to ensure that your parameter settings generalize well across different subsets of your data.\n",
    "###### By systematically experimenting with these parameters and evaluating their impact on your search results, you can find the optimal settings for your specific application. Keep in mind that the best values for k1 and b can vary depending on the characteristics of your dataset and the nature of your queries. \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fea39934-dbdc-447c-956a-557d9916583f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\oscarahe\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best k1: 2.0, Best b: 0.85, Best Average Score: 11.73482654569936\n",
      "Top 5 most similar sightings:\n",
      "              id rev is_current     updated_date system_updated_date  \\\n",
      "419  14018925189  15          1  7/18/2023 22:17     4/22/2024 21:50   \n",
      "170  14018331720  41          1  2/27/2023 16:01     4/22/2024 21:33   \n",
      "135  14019177987  18          1  5/26/2023 15:23     4/22/2024 21:58   \n",
      "294  14019569295  18          1  6/30/2023 19:40     4/22/2024 22:10   \n",
      "330  14019101636  23          1  3/15/2024 20:22     4/22/2024 21:56   \n",
      "\n",
      "                                             read_grps  read_grps_id  \\\n",
      "419  sys_admin,sighting_central_proj_admin,sighting...  2.201996e+10   \n",
      "170  sys_admin,sighting_central_proj_admin,sighting...  2.201995e+10   \n",
      "135  sys_admin,sighting_central_proj_admin,sighting...  2.201995e+10   \n",
      "294  sys_admin,sighting_central_proj_admin,soc_conf...  2.201996e+10   \n",
      "330  sys_admin,sighting_central_proj_admin,sighting...  2.201996e+10   \n",
      "\n",
      "      subject            tenant   submitted_date  ... local_updated_date  \\\n",
      "419  sighting  sighting_central  3/14/2023 23:26  ...    4/22/2024 21:50   \n",
      "170  sighting  sighting_central    1/4/2023 3:22  ...    4/22/2024 21:33   \n",
      "135  sighting  sighting_central  4/19/2023 16:24  ...    4/22/2024 21:58   \n",
      "294  sighting  sighting_central   6/9/2023 16:04  ...    4/22/2024 22:10   \n",
      "330  sighting  sighting_central   4/5/2023 15:19  ...    4/22/2024 21:56   \n",
      "\n",
      "    sighting_central.sighting.sw_fw_fixability_estimate  \\\n",
      "419                                                NaN    \n",
      "170                                                NaN    \n",
      "135                                                NaN    \n",
      "294                                                NaN    \n",
      "330                                                NaN    \n",
      "\n",
      "    sighting_central.sighting.customer_visible  \\\n",
      "419                                        NaN   \n",
      "170                                        NaN   \n",
      "135                                        NaN   \n",
      "294                                        NaN   \n",
      "330                                        NaN   \n",
      "\n",
      "    sighting_central.sighting.impact sighting_central.sighting.bug_reason  \\\n",
      "419                              NaN                                  NaN   \n",
      "170                              NaN                                  NaN   \n",
      "135                              NaN                                  NaN   \n",
      "294                              NaN                                  NaN   \n",
      "330                              NaN                                  NaN   \n",
      "\n",
      "                                         collaborators user_acl  \\\n",
      "419                joguevar,daalonso,dkrueger,gfuentes      NaN   \n",
      "170  joseator,kwadams,joguevar,cagalind,daalonso,sy...      NaN   \n",
      "135                         gfuentes,joguevar,daalonso      NaN   \n",
      "294                  larodri,daalonso,cdaffron,mcpeach      NaN   \n",
      "330  ombecerr,mcpeach,mrtruehe,daalonso,afrazier,le...      NaN   \n",
      "\n",
      "    sighting_central.sighting.beat_escape_reason_details  \\\n",
      "419                                                NaN     \n",
      "170                                                NaN     \n",
      "135                                                NaN     \n",
      "294                                                NaN     \n",
      "330                                                NaN     \n",
      "\n",
      "    sighting_central.sighting.symptom ww_local_updated_date  \n",
      "419                               NaN              2024ww17  \n",
      "170                               NaN              2024ww17  \n",
      "135                               NaN              2024ww17  \n",
      "294                               NaN              2024ww17  \n",
      "330                               NaN              2024ww17  \n",
      "\n",
      "[5 rows x 333 columns]\n",
      "419    <p>EMR A0 PCIE Gen4 RxCEM test is having error...\n",
      "170    <p>Problem description:</p><p><br /></p><p><sp...\n",
      "135    <p>EMR MCC R0 PCIE Gen5 RxCEM test presenting ...\n",
      "294    <p>64E PCIE lanes for Q3AN qdf is fused as 64C...\n",
      "330    <p>[EMR A0] Lane dropping on 1dpc @5600 SK hyn...\n",
      "Name: description, dtype: object\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from rank_bm25 import BM25Okapi\n",
    "from sklearn.feature_extraction.text import ENGLISH_STOP_WORDS\n",
    "from nltk.stem import PorterStemmer\n",
    "from nltk.corpus import wordnet\n",
    "import nltk\n",
    "\n",
    "# Ensure NLTK resources are available\n",
    "nltk.download('wordnet')\n",
    "\n",
    "# Load the Excel file\n",
    "file_path = 'C:/Users/oscarahe/OneDrive - Intel Corporation/Desktop/Exceles/query2.csv'  # Replace with your file path\n",
    "df = pd.read_csv(file_path)\n",
    "\n",
    "# Select the column to compare against\n",
    "column_to_compare = 'description'  # Replace with your column name\n",
    "\n",
    "# Initialize stemmer\n",
    "stemmer = PorterStemmer()\n",
    "\n",
    "# Preprocess the text data\n",
    "def preprocess_text(text):\n",
    "    text = str(text).lower()\n",
    "    tokens = [stemmer.stem(word) for word in text.split() if word not in ENGLISH_STOP_WORDS]\n",
    "    return tokens\n",
    "\n",
    "# Expand query with synonyms\n",
    "def expand_query(query):\n",
    "    expanded_query = set(query)\n",
    "    for word in query:\n",
    "        for syn in wordnet.synsets(word):\n",
    "            for lemma in syn.lemmas():\n",
    "                expanded_query.add(stemmer.stem(lemma.name()))\n",
    "    return list(expanded_query)\n",
    "\n",
    "# Preprocess the data in the selected column\n",
    "documents = df[column_to_compare].apply(preprocess_text).tolist()\n",
    "\n",
    "# Statement to compare\n",
    "statement = \"Crosstalk in PCIe lanes\"  # Replace with your statement\n",
    "query = preprocess_text(statement)\n",
    "\n",
    "# Expand the query\n",
    "expanded_query = expand_query(query)\n",
    "\n",
    "# Define a function to perform grid search for k1 and b\n",
    "def grid_search_bm25(documents, query, k1_values, b_values, top_n=5):\n",
    "    best_k1 = None\n",
    "    best_b = None\n",
    "    best_score = -1\n",
    "    best_sightings = None\n",
    "\n",
    "    for k1 in k1_values:\n",
    "        for b in b_values:\n",
    "            bm25 = BM25Okapi(documents, k1=k1, b=b)\n",
    "            scores = bm25.get_scores(query)\n",
    "            top_indices = scores.argsort()[-top_n:][::-1]\n",
    "            top_sightings = df.iloc[top_indices]\n",
    "            avg_score = scores[top_indices].mean()\n",
    "\n",
    "            if avg_score > best_score:\n",
    "                best_score = avg_score\n",
    "                best_k1 = k1\n",
    "                best_b = b\n",
    "                best_sightings = top_sightings\n",
    "\n",
    "    return best_k1, best_b, best_score, best_sightings\n",
    "\n",
    "# Define ranges for k1 and b\n",
    "k1_values = [1.2, 1.5, 1.8, 2.0]\n",
    "b_values = [0.5, 0.75, 0.85]\n",
    "\n",
    "# Perform grid search\n",
    "best_k1, best_b, best_score, best_sightings = grid_search_bm25(documents, expanded_query, k1_values, b_values)\n",
    "\n",
    "print(f\"Best k1: {best_k1}, Best b: {best_b}, Best Average Score: {best_score}\")\n",
    "print(\"Top 5 most similar sightings:\")\n",
    "print(best_sightings)\n",
    "print(best_sightings[column_to_compare])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "53882716-0a95-4259-952d-d3633d592593",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\oscarahe\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best k1: 2.0, Best b: 0.85, Best Average Score: 9.042068019835407\n",
      "Top 5 most similar sightings:\n",
      "3      Observing completely closed eye once xtalk is ...\n",
      "2      Observing failing Rx JTOL results at 85C .92V ...\n",
      "125    As reported in a customer IPS and shown by our...\n",
      "422    PCIE Gen5 Tx Jitter base measurements from EMR...\n",
      "39     ** Cloned new sighting fromÂ [EMR A0 PO][2S]: P...\n",
      "389    Description:System is not booting to OS with w...\n",
      "419    EMR A0 PCIE Gen4 RxCEM test is having errors a...\n",
      "136    RxLEQ data from XCC and MCC is showing that fo...\n",
      "266    There is a shortfall in write BW observed when...\n",
      "427    Actual Behavior:Socket Power Limit Indicator v...\n",
      "Name: description_clean, dtype: object\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from rank_bm25 import BM25Okapi\n",
    "from sklearn.feature_extraction.text import ENGLISH_STOP_WORDS\n",
    "from nltk.stem import PorterStemmer\n",
    "from nltk.corpus import wordnet\n",
    "import nltk\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "# Ensure NLTK resources are available\n",
    "nltk.download('wordnet')\n",
    "\n",
    "# Load the Excel file\n",
    "file_path = 'C:/Users/oscarahe/OneDrive - Intel Corporation/Desktop/Exceles/query2.csv'  # Replace with your file path\n",
    "df = pd.read_csv(file_path)\n",
    "\n",
    "# Select the column to compare against\n",
    "column_to_compare = 'description'  # Replace with your column name\n",
    "\n",
    "# Function to remove HTML tags\n",
    "def remove_html_malformed(text):\n",
    "    \"\"\"Remove HTML tags from a malformed HTML string using BeautifulSoup.\"\"\"\n",
    "    soup = BeautifulSoup(str(text), \"html.parser\")\n",
    "    return soup.get_text()\n",
    "\n",
    "# Clean the description column\n",
    "df['description_clean'] = df[column_to_compare].apply(remove_html_malformed)\n",
    "column_to_compare = 'description_clean'  # Use the cleaned column for further processing\n",
    "\n",
    "# Initialize stemmer\n",
    "stemmer = PorterStemmer()\n",
    "\n",
    "# Preprocess the text data\n",
    "def preprocess_text(text):\n",
    "    text = str(text).lower()\n",
    "    tokens = [stemmer.stem(word) for word in text.split() if word not in ENGLISH_STOP_WORDS]\n",
    "    return tokens\n",
    "\n",
    "# Expand query with synonyms\n",
    "def expand_query(query):\n",
    "    expanded_query = set(query)\n",
    "    for word in query:\n",
    "        for syn in wordnet.synsets(word):\n",
    "            for lemma in syn.lemmas():\n",
    "                expanded_query.add(stemmer.stem(lemma.name()))\n",
    "    return list(expanded_query)\n",
    "\n",
    "# Preprocess the data in the selected column\n",
    "documents = df[column_to_compare].apply(preprocess_text).tolist()\n",
    "\n",
    "# Statement to compare\n",
    "statement = \"Xtalk PCIE Express\"  # Replace with your statement\n",
    "query = preprocess_text(statement)\n",
    "\n",
    "# Expand the query\n",
    "expanded_query = expand_query(query)\n",
    "\n",
    "# Define a function to perform grid search for k1 and b\n",
    "def grid_search_bm25(documents, query, k1_values, b_values, top_n=10):\n",
    "    best_k1 = None\n",
    "    best_b = None\n",
    "    best_score = -1\n",
    "    best_sightings = None\n",
    "\n",
    "    for k1 in k1_values:\n",
    "        for b in b_values:\n",
    "            bm25 = BM25Okapi(documents, k1=k1, b=b)\n",
    "            scores = bm25.get_scores(query)\n",
    "            top_indices = scores.argsort()[-top_n:][::-1]\n",
    "            top_sightings = df.iloc[top_indices]\n",
    "            avg_score = scores[top_indices].mean()\n",
    "\n",
    "            if avg_score > best_score:\n",
    "                best_score = avg_score\n",
    "                best_k1 = k1\n",
    "                best_b = b\n",
    "                best_sightings = top_sightings\n",
    "\n",
    "    return best_k1, best_b, best_score, best_sightings\n",
    "\n",
    "# Define ranges for k1 and b\n",
    "k1_values = [1.2, 1.5, 1.8, 2.0]\n",
    "b_values = [0.5, 0.75, 0.85]\n",
    "\n",
    "# Perform grid search\n",
    "best_k1, best_b, best_score, best_sightings = grid_search_bm25(documents, expanded_query, k1_values, b_values)\n",
    "\n",
    "print(f\"Best k1: {best_k1}, Best b: {best_b}, Best Average Score: {best_score}\")\n",
    "print(\"Top 5 most similar sightings:\")\n",
    "print(best_sightings[column_to_compare])  # This prints only the cleaned descriptions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "15242197-3fc7-47dc-bc65-bd2400d42c04",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\oscarahe\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best k1: 2.0, Best b: 0.85, Best Average Score: 3.0754855373393717\n",
      "Top 5 most similar sightings:\n",
      "             ID                                Failure Description    Status  \\\n",
      "12  14017827596  PI5 pcode_sa fuse disable incorrectly programmed.  Complete   \n",
      "29  14018570336  Host 2971 reports width degradation or links g...  Complete   \n",
      "8   14020175013  When tuning the EMR EPP settings for the impro...  Rejected   \n",
      "10  14017677523  The first EMR fused part provisioned with debu...  Complete   \n",
      "7   14019985093  From the A1 VV 100 Boot Training Repeatability...  Rejected   \n",
      "\n",
      "                                               Theory  \\\n",
      "12  Wrong fuses provided by HVM, root caused by An...   \n",
      "29  Test card issue, need to follow up with that t...   \n",
      "8   Tuning changes at this point in the project ne...   \n",
      "10  Root Cause: lockout bit for S3M was not fused....   \n",
      "7                                       Not a defect.   \n",
      "\n",
      "                                      Conducted Tests  \n",
      "12  Booted both parts with Q1CA static fuses. Narr...  \n",
      "29  Issue was not observed in every single cold re...  \n",
      "8   The decision was made to change the slope valu...  \n",
      "10  Kicked off TF to tackle the issue. Debugging i...  \n",
      "7   The team agreed that despite the flat DFE resp...  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from rank_bm25 import BM25Okapi\n",
    "from sklearn.feature_extraction.text import ENGLISH_STOP_WORDS\n",
    "from nltk.stem import PorterStemmer\n",
    "from transformers import BertTokenizer, BertModel\n",
    "import torch\n",
    "import nltk\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "# Ensure NLTK resources are available\n",
    "nltk.download('wordnet')\n",
    "\n",
    "# Load the Excel file\n",
    "file_path = 'C:/Users/oscarahe/OneDrive - Intel Corporation/Desktop/Exceles/valgpt.csv'  # Replace with your file path\n",
    "df = pd.read_csv(file_path)\n",
    "\n",
    "# Columns to compare against\n",
    "columns_to_compare = ['Failure Description','Conducted Tests',\"Theory\"]  # Add more columns as needed\n",
    "\n",
    "# Initialize stemmer\n",
    "stemmer = PorterStemmer()\n",
    "\n",
    "# Preprocess the text data\n",
    "def preprocess_text(text):\n",
    "    text = str(text).lower()\n",
    "    # Tokenize, stem, and remove stop words\n",
    "    tokens = [stemmer.stem(word) for word in text.split() if word not in ENGLISH_STOP_WORDS]\n",
    "    return tokens\n",
    "\n",
    "# Load BERT model and tokenizer\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "model = BertModel.from_pretrained('bert-base-uncased')\n",
    "\n",
    "# Generate embeddings using BERT\n",
    "def generate_embeddings(text):\n",
    "    inputs = tokenizer(text, return_tensors='pt', truncation=True, padding=True)\n",
    "    outputs = model(**inputs)\n",
    "    return outputs.last_hidden_state.mean(dim=1)\n",
    "\n",
    "# Generate embeddings for all unique terms in the dataset\n",
    "unique_terms = set()\n",
    "for col in columns_to_compare:\n",
    "    for text in df[col]:\n",
    "        unique_terms.update(preprocess_text(text))\n",
    "\n",
    "term_embeddings = {term: generate_embeddings(term) for term in unique_terms}\n",
    "\n",
    "# Expand query using BERT embeddings\n",
    "def expand_query_with_bert(query):\n",
    "    query_embedding = generate_embeddings(query)\n",
    "    similarities = {}\n",
    "\n",
    "    for term, embedding in term_embeddings.items():\n",
    "        similarity = cosine_similarity(query_embedding.detach().numpy(), embedding.detach().numpy())[0][0]\n",
    "        similarities[term] = similarity\n",
    "\n",
    "    # Select top N related terms based on similarity\n",
    "    top_n = 5\n",
    "    related_terms = sorted(similarities, key=similarities.get, reverse=True)[:top_n]\n",
    "    \n",
    "    # Combine original query with related terms\n",
    "    expanded_query = query.split() + related_terms\n",
    "    return expanded_query\n",
    "\n",
    "# Preprocess the data in the selected columns\n",
    "documents_per_column = {col: df[col].apply(preprocess_text).tolist() for col in columns_to_compare}\n",
    "\n",
    "# Statement to compare\n",
    "statement = \"Crostalk\"  # Replace with your statement\n",
    "query = preprocess_text(statement)\n",
    "\n",
    "# Expand the query using BERT\n",
    "expanded_query = expand_query_with_bert(statement)\n",
    "\n",
    "# Define a function to perform grid search for k1 and b\n",
    "def grid_search_bm25(documents_per_column, query, k1_values, b_values, top_n=5):\n",
    "    best_k1 = None\n",
    "    best_b = None\n",
    "    best_score = -1\n",
    "    best_sightings = None\n",
    "\n",
    "    for k1 in k1_values:\n",
    "        for b in b_values:\n",
    "            combined_scores = None\n",
    "\n",
    "            for col, documents in documents_per_column.items():\n",
    "                bm25 = BM25Okapi(documents, k1=k1, b=b)\n",
    "                scores = bm25.get_scores(query)\n",
    "\n",
    "                if combined_scores is None:\n",
    "                    combined_scores = scores\n",
    "                else:\n",
    "                    combined_scores += scores\n",
    "\n",
    "            top_indices = combined_scores.argsort()[-top_n:][::-1]\n",
    "            top_sightings = df.iloc[top_indices]\n",
    "            avg_score = combined_scores[top_indices].mean()\n",
    "\n",
    "            if avg_score > best_score:\n",
    "                best_score = avg_score\n",
    "                best_k1 = k1\n",
    "                best_b = b\n",
    "                best_sightings = top_sightings\n",
    "\n",
    "    return best_k1, best_b, best_score, best_sightings\n",
    "\n",
    "# Define ranges for k1 and b\n",
    "k1_values = [1.2, 1.5, 1.8, 2.0]\n",
    "b_values = [0.5, 0.75, 0.85]\n",
    "\n",
    "# Perform grid search\n",
    "best_k1, best_b, best_score, best_sightings = grid_search_bm25(documents_per_column, expanded_query, k1_values, b_values)\n",
    "\n",
    "print(f\"Best k1: {best_k1}, Best b: {best_b}, Best Average Score: {best_score}\")\n",
    "print(\"Top 5 most similar sightings:\")\n",
    "print(best_sightings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58dff58b-49dc-43cc-8f7f-7c0c9e4f83ef",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
