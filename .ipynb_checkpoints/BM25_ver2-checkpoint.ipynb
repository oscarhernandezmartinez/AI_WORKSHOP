{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9b21d840-2b0f-4d8c-afce-063e71acbe18",
   "metadata": {},
   "source": [
    "###### The BM25 algorithm is designed to rank documents based on the relevance of terms in a query, considering factors like term frequency and document length. However, if your query doesn't match any documents exactly, you might need to adjust your approach to improve the similarity detection. Here are some strategies to enhance the effectiveness of BM25 in finding more relevant matches:\n",
    "######  Implemnted in this new script\n",
    "###### Synonyms and Stemming: Use techniques like stemming or lemmatization to reduce words to their base forms, and consider expanding your query with synonyms to capture more variations of the terms. \n",
    "###### Query Expansion: Manually or automatically expand your query with related terms. This can be done using a thesaurus or word embeddings like Word2Vec or GloVe to find semantically similar words.\n",
    "###### Preprocessing Enhancements: Improve your preprocessing steps by removing noise, handling typos, and ensuring consistent formatting across your dataset.\n",
    "###### Custom Scoring: Consider implementing a custom scoring function that combines BM25 with other metrics, such as semantic similarity using embeddings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2138a96c-e16b-4b1a-87ab-829dad563560",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 5 most similar sightings:\n",
      "             ID                                Failure Description    Status  \\\n",
      "18  14018000516  Wrong Turbo Bin bucket 7 impacting PO, VIS-1 S...  Complete   \n",
      "19  14018000574  Wrong pcode_config_tdp_level_en_mask fuse valu...  Rejected   \n",
      "17  14018000504  Wrong mapping on SST-TF mailbox for Cdyn level...  Complete   \n",
      "23  14018183474  Wrong mapping on SST-TF mailbox for Cdyn level...  Complete   \n",
      "35  14018874246  During VV for EMR A0 we observed a failure wit...  Complete   \n",
      "\n",
      "                                               Theory  \\\n",
      "18    The issue was related to incorrect fuse values.   \n",
      "19  The issue was identified as a fusing issue, no...   \n",
      "17        The issue was due to an outdated CRIF file.   \n",
      "23        The issue was due to an outdated CRIF file.   \n",
      "35  Known bug from ICX and SPR A0. Was not documen...   \n",
      "\n",
      "                                      Conducted Tests  \n",
      "18   The problem was resolved by cloning to Fuse CCB.  \n",
      "19  The problem was resolved by correcting the fus...  \n",
      "17  The problem was resolved with a CRIF file upda...  \n",
      "23  The problem was resolved with a CRIF file upda...  \n",
      "35  FV team needs to modify their post test to ign...  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\fsalasb\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from rank_bm25 import BM25Okapi\n",
    "from sklearn.feature_extraction.text import ENGLISH_STOP_WORDS\n",
    "from nltk.stem import PorterStemmer\n",
    "from nltk.corpus import wordnet\n",
    "import nltk\n",
    "\n",
    "# Ensure NLTK resources are available\n",
    "nltk.download('wordnet')\n",
    "\n",
    "# Load the Excel file\n",
    "file_path = 'C:/Users/fsalasb/OneDrive - Intel Corporation/Documents/AI Workshop/EMR Sightings Valgpt.xlsx'  # Replace with your file path\n",
    "df = pd.read_excel(file_path)\n",
    "\n",
    "# Select the column to compare against\n",
    "column_to_compare = 'Failure Description'  # Replace with your column name\n",
    "\n",
    "# Initialize stemmer. This helps to reduce words to their base forms. New feature\n",
    "stemmer = PorterStemmer()\n",
    "\n",
    "# Preprocess the text data\n",
    "def preprocess_text(text):\n",
    "    # Convert to lowercase\n",
    "    text = str(text).lower()\n",
    "    # Tokenize, stem, and remove stop words\n",
    "    tokens = [stemmer.stem(word) for word in text.split() if word not in ENGLISH_STOP_WORDS]\n",
    "    return tokens\n",
    "\n",
    "# Expand query with synonyms. This is a new feature. \n",
    "def expand_query(query):\n",
    "    expanded_query = set(query)\n",
    "    for word in query:\n",
    "        for syn in wordnet.synsets(word):\n",
    "            for lemma in syn.lemmas():\n",
    "                expanded_query.add(stemmer.stem(lemma.name()))\n",
    "    return list(expanded_query)\n",
    "\n",
    "# Preprocess the data in the selected column\n",
    "documents = df[column_to_compare].apply(preprocess_text).tolist()\n",
    "\n",
    "# Initialize BM25\n",
    "bm25 = BM25Okapi(documents)\n",
    "\n",
    "# Statement to compare\n",
    "statement = \"Incorrect values may be observed in Turbo Bin Bucket 7\"  # Replace with your statement\n",
    "query = preprocess_text(statement)\n",
    "\n",
    "# Expand the query\n",
    "expanded_query = expand_query(query)\n",
    "\n",
    "# Get BM25 scores\n",
    "scores = bm25.get_scores(expanded_query)\n",
    "\n",
    "# Find the indices of the top 5 scores\n",
    "top_n = 5\n",
    "top_indices = scores.argsort()[-top_n:][::-1]\n",
    "\n",
    "# Get the top 5 most similar sightings\n",
    "top_sightings = df.iloc[top_indices]\n",
    "\n",
    "print(\"Top 5 most similar sightings:\")\n",
    "print(top_sightings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "656271ee-f2fa-4634-ab26-7550962149c1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
